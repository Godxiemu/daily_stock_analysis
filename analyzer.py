# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ - AIåˆ†æå±‚
===================================

èŒè´£ï¼š
1. å°è£… Gemini API è°ƒç”¨é€»è¾‘
2. åˆ©ç”¨ Google Search Grounding è·å–å®æ—¶æ–°é—»
3. ç»“åˆæŠ€æœ¯é¢å’Œæ¶ˆæ¯é¢ç”Ÿæˆåˆ†ææŠ¥å‘Š
"""

import json
import logging
import time
from dataclasses import dataclass
from typing import Optional, Dict, Any, List

from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log,
)

from config import get_config

logger = logging.getLogger(__name__)


# è‚¡ç¥¨åç§°æ˜ å°„ï¼ˆå¸¸è§è‚¡ç¥¨ï¼‰
STOCK_NAME_MAP = {
    # å¸¸è§è‚¡ç¥¨
    '600519': 'è´µå·èŒ…å°',
    '000001': 'å¹³å®‰é“¶è¡Œ',
    '300750': 'å®å¾·æ—¶ä»£',
    '002594': 'æ¯”äºšè¿ª',
    '600036': 'æ‹›å•†é“¶è¡Œ',
    '601318': 'ä¸­å›½å¹³å®‰',
    '000858': 'äº”ç²®æ¶²',
    '600276': 'æ’ç‘åŒ»è¯',
    '601012': 'éš†åŸºç»¿èƒ½',
    '002475': 'ç«‹è®¯ç²¾å¯†',
    '300059': 'ä¸œæ–¹è´¢å¯Œ',
    '002415': 'æµ·åº·å¨è§†',
    '600900': 'é•¿æ±Ÿç”µåŠ›',
    '601166': 'å…´ä¸šé“¶è¡Œ',
    '600028': 'ä¸­å›½çŸ³åŒ–',
    # ç”¨æˆ·è‡ªé€‰è‚¡ï¼ˆAPIå…œåº•ï¼‰
    '002379': 'å®æ¡¥æ§è‚¡',
    '002170': 'ä¸­åŸºå¥åº·',
    '600015': 'åå¤é“¶è¡Œ',
    '002749': 'å¼€æ¶¦è‚¡ä»½',
    '600256': 'å¹¿æ±‡èƒ½æº',
    '601899': 'ç´«é‡‘çŸ¿ä¸š',
    '601198': 'ä¸œå…´è¯åˆ¸',
}


@dataclass
class AnalysisResult:
    """
    AI åˆ†æç»“æœæ•°æ®ç±» - å†³ç­–ä»ªè¡¨ç›˜ç‰ˆ
    
    å°è£… Gemini è¿”å›çš„åˆ†æç»“æœï¼ŒåŒ…å«å†³ç­–ä»ªè¡¨ç›˜å’Œè¯¦ç»†åˆ†æ
    """
    code: str
    name: str
    
    # ========== æ ¸å¿ƒæŒ‡æ ‡ ==========
    sentiment_score: int  # ç»¼åˆè¯„åˆ† 0-100 (>70å¼ºçƒˆçœ‹å¤š, >60çœ‹å¤š, 40-60éœ‡è¡, <40çœ‹ç©º)
    trend_prediction: str  # è¶‹åŠ¿é¢„æµ‹ï¼šå¼ºçƒˆçœ‹å¤š/çœ‹å¤š/éœ‡è¡/çœ‹ç©º/å¼ºçƒˆçœ‹ç©º
    operation_advice: str  # æ“ä½œå»ºè®®ï¼šä¹°å…¥/åŠ ä»“/æŒæœ‰/å‡ä»“/å–å‡º/è§‚æœ›
    confidence_level: str = "ä¸­"  # ç½®ä¿¡åº¦ï¼šé«˜/ä¸­/ä½
    
    # ========== å†³ç­–ä»ªè¡¨ç›˜ (æ–°å¢) ==========
    dashboard: Optional[Dict[str, Any]] = None  # å®Œæ•´çš„å†³ç­–ä»ªè¡¨ç›˜æ•°æ®
    
    # ========== èµ°åŠ¿åˆ†æ ==========
    trend_analysis: str = ""  # èµ°åŠ¿å½¢æ€åˆ†æï¼ˆæ”¯æ’‘ä½ã€å‹åŠ›ä½ã€è¶‹åŠ¿çº¿ç­‰ï¼‰
    short_term_outlook: str = ""  # çŸ­æœŸå±•æœ›ï¼ˆ1-3æ—¥ï¼‰
    medium_term_outlook: str = ""  # ä¸­æœŸå±•æœ›ï¼ˆ1-2å‘¨ï¼‰
    
    # ========== æŠ€æœ¯é¢åˆ†æ ==========
    technical_analysis: str = ""  # æŠ€æœ¯æŒ‡æ ‡ç»¼åˆåˆ†æ
    ma_analysis: str = ""  # å‡çº¿åˆ†æï¼ˆå¤šå¤´/ç©ºå¤´æ’åˆ—ï¼Œé‡‘å‰/æ­»å‰ç­‰ï¼‰
    volume_analysis: str = ""  # é‡èƒ½åˆ†æï¼ˆæ”¾é‡/ç¼©é‡ï¼Œä¸»åŠ›åŠ¨å‘ç­‰ï¼‰
    pattern_analysis: str = ""  # Kçº¿å½¢æ€åˆ†æ
    
    # ========== åŸºæœ¬é¢åˆ†æ ==========
    fundamental_analysis: str = ""  # åŸºæœ¬é¢ç»¼åˆåˆ†æ
    sector_position: str = ""  # æ¿å—åœ°ä½å’Œè¡Œä¸šè¶‹åŠ¿
    company_highlights: str = ""  # å…¬å¸äº®ç‚¹/é£é™©ç‚¹
    
    # ========== æƒ…ç»ªé¢/æ¶ˆæ¯é¢åˆ†æ ==========
    news_summary: str = ""  # è¿‘æœŸé‡è¦æ–°é—»/å…¬å‘Šæ‘˜è¦
    market_sentiment: str = ""  # å¸‚åœºæƒ…ç»ªåˆ†æ
    hot_topics: str = ""  # ç›¸å…³çƒ­ç‚¹è¯é¢˜
    
    # ========== ç»¼åˆåˆ†æ ==========
    analysis_summary: str = ""  # ç»¼åˆåˆ†ææ‘˜è¦
    key_points: str = ""  # æ ¸å¿ƒçœ‹ç‚¹ï¼ˆ3-5ä¸ªè¦ç‚¹ï¼‰
    risk_warning: str = ""  # é£é™©æç¤º
    buy_reason: str = ""  # ä¹°å…¥/å–å‡ºç†ç”±
    
    # ========== å…ƒæ•°æ® ==========
    raw_response: Optional[str] = None  # åŸå§‹å“åº”ï¼ˆè°ƒè¯•ç”¨ï¼‰
    search_performed: bool = False  # æ˜¯å¦æ‰§è¡Œäº†è”ç½‘æœç´¢
    data_sources: str = ""  # æ•°æ®æ¥æºè¯´æ˜
    success: bool = True
    error_message: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'code': self.code,
            'name': self.name,
            'sentiment_score': self.sentiment_score,
            'trend_prediction': self.trend_prediction,
            'operation_advice': self.operation_advice,
            'confidence_level': self.confidence_level,
            'dashboard': self.dashboard,  # å†³ç­–ä»ªè¡¨ç›˜æ•°æ®
            'trend_analysis': self.trend_analysis,
            'short_term_outlook': self.short_term_outlook,
            'medium_term_outlook': self.medium_term_outlook,
            'technical_analysis': self.technical_analysis,
            'ma_analysis': self.ma_analysis,
            'volume_analysis': self.volume_analysis,
            'pattern_analysis': self.pattern_analysis,
            'fundamental_analysis': self.fundamental_analysis,
            'sector_position': self.sector_position,
            'company_highlights': self.company_highlights,
            'news_summary': self.news_summary,
            'market_sentiment': self.market_sentiment,
            'hot_topics': self.hot_topics,
            'analysis_summary': self.analysis_summary,
            'key_points': self.key_points,
            'risk_warning': self.risk_warning,
            'buy_reason': self.buy_reason,
            'search_performed': self.search_performed,
            'success': self.success,
            'error_message': self.error_message,
        }
    
    def get_core_conclusion(self) -> str:
        """è·å–æ ¸å¿ƒç»“è®ºï¼ˆä¸€å¥è¯ï¼‰"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            return self.dashboard['core_conclusion'].get('one_sentence', self.analysis_summary)
        return self.analysis_summary
    
    def get_position_advice(self, has_position: bool = False) -> str:
        """è·å–æŒä»“å»ºè®®"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            pos_advice = self.dashboard['core_conclusion'].get('position_advice', {})
            if has_position:
                return pos_advice.get('has_position', self.operation_advice)
            return pos_advice.get('no_position', self.operation_advice)
        return self.operation_advice
    
    def get_sniper_points(self) -> Dict[str, str]:
        """è·å–ç‹™å‡»ç‚¹ä½"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('sniper_points', {})
        return {}
    
    def get_checklist(self) -> List[str]:
        """è·å–æ£€æŸ¥æ¸…å•"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('action_checklist', [])
        return []
    
    def get_risk_alerts(self) -> List[str]:
        """è·å–é£é™©è­¦æŠ¥"""
        if self.dashboard and 'intelligence' in self.dashboard:
            return self.dashboard['intelligence'].get('risk_alerts', [])
        return []
    
    def get_emoji(self) -> str:
        """æ ¹æ®æ“ä½œå»ºè®®è¿”å›å¯¹åº” emoji"""
        emoji_map = {
            'ä¹°å…¥': 'ğŸŸ¢',
            'åŠ ä»“': 'ğŸŸ¢',
            'å¼ºçƒˆä¹°å…¥': 'ğŸ’š',
            'æŒæœ‰': 'ğŸŸ¡',
            'è§‚æœ›': 'âšª',
            'å‡ä»“': 'ğŸŸ ',
            'å–å‡º': 'ğŸ”´',
            'å¼ºçƒˆå–å‡º': 'âŒ',
        }
        return emoji_map.get(self.operation_advice, 'ğŸŸ¡')
    
    def get_confidence_stars(self) -> str:
        """è¿”å›ç½®ä¿¡åº¦æ˜Ÿçº§"""
        star_map = {'é«˜': 'â­â­â­', 'ä¸­': 'â­â­', 'ä½': 'â­'}
        return star_map.get(self.confidence_level, 'â­â­')


class GeminiAnalyzer:
    """
    Gemini AI åˆ†æå™¨
    
    èŒè´£ï¼š
    1. è°ƒç”¨ Google Gemini API è¿›è¡Œè‚¡ç¥¨åˆ†æ
    2. ç»“åˆé¢„å…ˆæœç´¢çš„æ–°é—»å’ŒæŠ€æœ¯é¢æ•°æ®ç”Ÿæˆåˆ†ææŠ¥å‘Š
    3. è§£æ AI è¿”å›çš„ JSON æ ¼å¼ç»“æœ
    
    ä½¿ç”¨æ–¹å¼ï¼š
        analyzer = GeminiAnalyzer()
        result = analyzer.analyze(context, news_context)
    """
    
    # ========================================
    # ç³»ç»Ÿæç¤ºè¯ - Dangæ°å†³ç­–ä»ªè¡¨ç›˜ v3.0
    # ========================================
    # èåˆ Dangæ°ä»·å€¼æŠ•èµ„ç†å¿µ + æŠ€æœ¯é¢è¶‹åŠ¿åˆ†æ
    # æ ¸å¿ƒï¼šåŸºæœ¬é¢ï¼ˆ60%ï¼‰+ æŠ€æœ¯é¢ï¼ˆ40%ï¼‰
    # ========================================
    
    SYSTEM_PROMPT = """
[Role Definition]
ä½ æ˜¯ä¸€ä¸ªåŸºäºâ€œMr. Dang ä»·å€¼æŠ•èµ„ä½“ç³»â€çš„**é«˜çº§é‡åŒ–å†³ç­–å¼•æ“**ã€‚
ä½ çš„æ ¸å¿ƒä»»åŠ¡ä¸æ˜¯é™ªèŠï¼Œè€Œæ˜¯å¯¹è¾“å…¥çš„è‚¡ç¥¨ä»£ç /åç§°è¿›è¡Œæ·±åº¦æ•°æ®æ¸…æ´—ä¸é€»è¾‘è¿ç®—ï¼Œè¾“å‡ºä¸€ä»½**å®¢è§‚ã€å†·å³»ã€æ— åºŸè¯**çš„ã€æŠ•èµ„å†³ç­–ä»ªè¡¨ç›˜ã€‘ã€‚

---

## ä¸€ã€æ ¸å¿ƒç®—æ³•é€»è¾‘ (Total Score: 100 Points)

### 1. åŸºç¡€é¢è¯„åˆ† (æƒé‡ 60åˆ†) - å†³å®šç”Ÿæ­»çš„é—¨æ§›
*é€»è¾‘æ ¸å¿ƒï¼šåªä¹°â€œ2æ±‚â€ä»¥ä¸Šçš„ç”Ÿäº§èµ„æ–™ï¼Œä¸”ä»·æ ¼å¿…é¡»ä¾¿å®œã€‚*

* **A. å•†ä¸šæ¨¡å¼ (20åˆ†)**
    * **3æ±‚ (20åˆ†)**ï¼šä¸Šæ¸¸æ±‚ã€ä¸‹æ¸¸æ±‚ã€æ”¿åºœæ±‚ (å¦‚å„æ–­è·¯æƒçš„é“è·¯ã€æ ¸å¿ƒçŸ¿å±±)ã€‚
    * **2æ±‚ (15åˆ†)**ï¼šæ‹¥æœ‰æå¼ºæˆæœ¬ä¼˜åŠ¿æˆ–ç‰Œç…§å£å’ (å¦‚æ°´ç”µé¾™å¤´ã€ç…¤ç‚­ç‹)ã€‚
    * **1æ±‚ (5åˆ†)**ï¼šæ™®é€šç«äº‰æ€§è¡Œä¸šã€‚
    * **0æ±‚ (0åˆ†)**ï¼šåœ°äº§ã€å»ºç­‘ã€æ— å£å’çš„ä¸­æ¸¸åˆ¶é€  (è°éƒ½ä¸æ±‚ä½ )ã€‚

* **B. ç°é‡‘æµå›æŠ¥ (20åˆ†)**
    * *æŒ‡æ ‡ï¼šé¢„æœŸè‚¡æ¯ç‡ (input: dividend_analysis.expected_yield)*
    * **â‰¥ 7% (20åˆ†)**ï¼šç°é‡‘å¥¶ç‰›ï¼Œæå…·å¸å¼•åŠ›ã€‚
    * **5% - 7% (15åˆ†)**ï¼šåˆæ ¼çš„ç”Ÿäº§èµ„æ–™ã€‚
    * **3% - 5% (10åˆ†)**ï¼šé¸¡è‚‹ã€‚
    * **< 3% (0åˆ†)**ï¼šä¸ä»…ä¸å¾—åˆ†ï¼Œè‹¥ä¸” PE > 30ï¼Œç›´æ¥è§†ä¸ºæ³¡æ²«ã€‚

* **C. ç»å¯¹ä¼°å€¼å®‰å…¨åº¦ (20åˆ†)**
    * *æ¨¡å‹åˆ†æµåˆ¤å®šï¼š*
        * **å‘¨æœŸ/èµ„æºè‚¡**ï¼šPE < 10 (+20åˆ†)ï¼›PE 10-15 (+15åˆ†)ï¼›PE > 20 (0åˆ†)ã€‚
        * **é“¶è¡Œè‚¡**ï¼šPE < 5 ä¸” PB < 0.6 (+20åˆ†)ï¼›PE 5-6 (+15åˆ†)ï¼›PE > 8 (0åˆ†)ã€‚
        * **å…¶ä»–è‚¡**ï¼šPE < 15 (+20åˆ†)ï¼›PE > 30 (0åˆ†)ã€‚

### 2. æ‹©æ—¶è¯„åˆ† (æƒé‡ 20åˆ†) - å¯»æ‰¾â€œé”™æ€â€æœºä¼š
*é€»è¾‘æ ¸å¿ƒï¼šä¸åšè¶‹åŠ¿è·Ÿéšï¼Œåªåšå·¦ä¾§ä½å¸ã€‚ä¹°åœ¨æ— äººé—®æ´¥å¤„ã€‚*

* **ä¹–ç¦»ç‡ (BIAS) è¯„åˆ†**
    * **é»„é‡‘å‘ (BIAS < -10%) -> 20åˆ†**ï¼šæåº¦è¶…è·Œï¼Œæƒ…ç»ªå†°ç‚¹ï¼Œä¹Ÿæ˜¯ä¹°ç‚¹ã€‚
    * **å›è°ƒåˆ°ä½ (BIAS -5% ~ 0%) -> 10åˆ†**ï¼šç¼©é‡å›è°ƒï¼Œé€‚åˆåˆ†æ‰¹å»ºä»“ã€‚
    * **æ— ä¼˜åŠ¿ (BIAS > 0%) -> 0åˆ†**ï¼šä»·æ ¼åœ¨å‡çº¿ä¸Šæ–¹ï¼Œæ²¡æœ‰æˆæœ¬ä¼˜åŠ¿ã€‚
    * *ç†”æ–­æœºåˆ¶ï¼šè‹¥ BIAS > 15% (ä¸¥é‡è¶…ä¹°)ï¼ŒæŠ€æœ¯é¢å¾—åˆ†å¼ºåˆ¶å½’é›¶ï¼Œå¹¶è§¦å‘é£æ§ã€‚*

### 3. æ¯”ä»·è¯„åˆ† (æƒé‡ 20åˆ†) - é¿å…â€œç¯ä¸‹é»‘â€
*é€»è¾‘æ ¸å¿ƒï¼šä¸ä»…è¦ä¾¿å®œï¼Œè¿˜è¦æ¯”å†å²ä¾¿å®œï¼Œæ¯”åŒè¡Œä¾¿å®œã€‚*

* **A. çºµå‘å†å²åˆ†ä½ (10åˆ†)**
    * **å‘¨æœŸè‚¡**ï¼šçœ‹ 10å¹´ PB åˆ†ä½ã€‚å¤„äºåº•éƒ¨ 0-20% åŒºé—´ -> **10åˆ†**ã€‚
    * **éå‘¨æœŸè‚¡**ï¼šçœ‹ 10å¹´ PE åˆ†ä½ã€‚å¤„äºåº•éƒ¨ 0-20% åŒºé—´ -> **10åˆ†**ã€‚
    * *å…¶ä»–åŒºé—´æŒ‰æ¯”ä¾‹é€’å‡ï¼Œè¶…è¿‡50%åˆ†ä½ä¸å¾—åˆ†ã€‚*
    * *(æ³¨ï¼šå¦‚ç¼ºå°‘å…·ä½“åˆ†ä½æ•°æ®ï¼Œè¯·æ ¹æ®å½“å‰ä¼°å€¼æ°´å¹³åˆç†ä¼°ç®—)*

* **B. æ¨ªå‘åŒä¸šäº’è¯„ (10åˆ†)**
    * **æ€§ä»·æ¯”ä¹‹ç‹ (10åˆ†)**ï¼šä¼°å€¼ä½äºåŒä¸šå‡å€¼ >10%ï¼Œä¸” ROE/è‚¡æ¯ç‡é«˜äºåŒä¸šã€‚
    * **åˆç†æŠ˜ä»· (5åˆ†)**ï¼šä¼°å€¼ç•¥ä½äºåŒä¸šã€‚
    * **æº¢ä»·/æ— ä¼˜åŠ¿ (0åˆ†)**ï¼šæ¯”åŒè¡Œè¿˜è´µï¼Œä¸”æ— æ˜æ˜¾é¾™å¤´é€»è¾‘ã€‚

### 4. é£é™©æƒ©ç½š (Risk Penalty) - ä¸€ç¥¨å¦å†³
* **é»‘åå•è¡Œä¸š**ï¼šå…‰ä¼ã€ç”µæ± ã€çº¯é¢˜æè‚¡ã€äºæŸè‚¡ -> **-20åˆ†**ã€‚
* **æŠ€æœ¯é¢è¿‡çƒ­**ï¼šBIAS > 15% æˆ– çŸ­æœŸæ¶¨å¹… > 30% -> **-20åˆ†**ã€‚
* **å‘¨æœŸé™·é˜±**ï¼šå‘¨æœŸè‚¡å¤„äºå†å²é«˜ä½(PBé«˜) ä½† PEæä½ -> **-50åˆ† (æåº¦å±é™©)**ã€‚

---

## äºŒã€è¾“å‡ºæ ¼å¼è¦æ±‚ (JSON Schema)

å¿…é¡»è¾“å‡ºä¸”ä»…è¾“å‡ºç¬¦åˆä»¥ä¸‹ JSON ç»“æ„çš„ valid JSONã€‚

```json
{
    "sentiment_score": æ€»è¯„åˆ† (0-100, åŸºäºä¸Šè¿°ç®—æ³•è®¡ç®—),
    "trend_prediction": "çœ‹å¤š/çœ‹ç©º/éœ‡è¡/è§‚å¯Ÿ",
    "operation_advice": "å¼ºåŠ›ä¹°å…¥/é€¢ä½å»ºä»“/ä¸­æ€§è§‚æœ›/å–å‡º",
    "confidence_level": "é«˜/ä¸­/ä½",
    
    "dashboard": {
        "header": {
            "industry_model": "å‘¨æœŸPBæ¨¡å‹ / é“¶è¡Œè‚¡æ¯æ¨¡å‹ / å¼±å‘¨æœŸPEæ¨¡å‹",
            "verdict": "åŸºäºå¾—åˆ†çš„å†³ç­–å»ºè®®"
        },
        
        "factor_details": {
            "business_model": {
                "score": 0-20,
                "status": "3æ±‚/2æ±‚/1æ±‚/0æ±‚",
                "evaluation": "æä¼˜/ä¼˜è‰¯/å¹³åº¸/å·®",
                "reason": "ç®€è¯„"
            },
            "cash_flow": {
                "score": 0-20,
                "yield": "è‚¡æ¯ç‡æ•°å€¼%",
                "evaluation": "ç°é‡‘å¥¶ç‰›/åŠæ ¼/é¸¡è‚‹",
                "reason": "ç®€è¯„"
            },
            "valuation_safety": {
                "score": 0-20,
                "metric_value": "PE/PBæ•°å€¼",
                "evaluation": "ä½ä¼°/åˆç†/é«˜ä¼°",
                "reason": "ç®€è¯„"
            },
            "technical_timing": {
                "score": 0-20,
                "bias_value": "BIASæ•°å€¼%",
                "evaluation": "é»„é‡‘å‘/å›è°ƒ/è¶…ä¹°",
                "reason": "ç®€è¯„"
            },
            "historical_comparison": {
                "score": 0-10,
                "rank_pct": "åˆ†ä½æ•°å€¼% (å¦‚æœ‰)",
                "evaluation": "å†å²åº•éƒ¨/åŠå±±è…°/é¡¶éƒ¨",
                "reason": "ç®€è¯„"
            },
            "peer_comparison": {
                "score": 0-10,
                "discount_pct": "æŠ˜ä»·æ¯”ä¾‹%",
                "evaluation": "ä¼˜äºåŒè¡Œ/æ— ä¼˜åŠ¿",
                "reason": "ç®€è¯„"
            },
            "risk_penalty": {
                "score": è´Ÿåˆ†,
                "flags": ["è§¦å‘çš„é£é™©é¡¹1", "è§¦å‘çš„é£é™©é¡¹2"]
            }
        },
        
        "deep_analysis": {
            "valuation_logic": "âš—ï¸ ä¼°å€¼ä¸æ¯”ä»·é€»è¾‘è¯Šæ–­æ–‡æ¡ˆ",
            "trading_scan": "ğŸ›¡ï¸ äº¤æ˜“å±‚é¢æ‰«ææ–‡æ¡ˆ",
            "risk_radar": "âš ï¸ é£é™©é›·è¾¾æ–‡æ¡ˆ (æ— é£é™©åˆ™æ˜¾ç¤ºæš‚æ— )"
        }
    },
    
    "analysis_summary": "100å­—å†…æ ¸å¿ƒç»“è®º (å¯¹åº”åŸ dashboard æ¨¡å—1)",
    "risk_warning": "ä¸€å¥è¯é£é™©æç¤º"
}
```

## ä¸‰ã€æ‰§è¡Œçº¦æŸ
1. **æ•°æ®ä¼˜å…ˆ**ï¼šä¸¥æ ¼ä¾æ®è¾“å…¥æ•°æ®æ‰“åˆ†ã€‚è‹¥ç¼ºå°‘ç²¾å‡†å†å²/åŒä¸šæ•°æ®ï¼Œè¯·åŸºäºä½ çš„é‡‘èå¸¸è¯†åº“è¿›è¡Œ**ä¿å®ˆä¼°ç®—**ï¼Œå¹¶åœ¨ç†ç”±ä¸­æ ‡æ³¨"(ä¼°ç®—)"ã€‚
2. **é€»è¾‘ä¸€è‡´æ€§**ï¼š`sentiment_score` å¿…é¡»ç­‰äºå„å› å­å¾—åˆ†ä¹‹å’Œã€‚
3. **é›¶åºŸè¯**ï¼šText å­—æ®µå†…å®¹å¿…é¡»å¹²ç»ƒå†·å³»ï¼Œä¸è¦å‡ºç°"æ ¹æ®åˆ†æ..."ç­‰åºŸè¯ã€‚
"""

    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ– AI åˆ†æå™¨
        
        ä¼˜å…ˆçº§ï¼šGemini > OpenAI å…¼å®¹ API
        
        Args:
            api_key: Gemini API Keyï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
        """
        config = get_config()
        self._api_key = api_key or config.gemini_api_key
        self._model = None
        self._current_model_name = None  # å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°
        self._using_fallback = False  # æ˜¯å¦æ­£åœ¨ä½¿ç”¨å¤‡é€‰æ¨¡å‹
        self._use_openai = False  # æ˜¯å¦ä½¿ç”¨ OpenAI å…¼å®¹ API
        self._openai_client = None  # OpenAI å®¢æˆ·ç«¯
        
        # æ£€æŸ¥ Gemini API Key æ˜¯å¦æœ‰æ•ˆï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
        gemini_key_valid = self._api_key and not self._api_key.startswith('your_') and len(self._api_key) > 10
        
        # ä¼˜å…ˆå°è¯•åˆå§‹åŒ– Gemini
        if gemini_key_valid:
            try:
                self._init_model()
            except Exception as e:
                logger.warning(f"Gemini åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°è¯• OpenAI å…¼å®¹ API")
                self._init_openai_fallback()
        else:
            # Gemini Key æœªé…ç½®ï¼Œå°è¯• OpenAI
            logger.info("Gemini API Key æœªé…ç½®ï¼Œå°è¯•ä½¿ç”¨ OpenAI å…¼å®¹ API")
            self._init_openai_fallback()
        
        # ä¸¤è€…éƒ½æœªé…ç½®
        if not self._model and not self._openai_client:
            logger.warning("æœªé…ç½®ä»»ä½• AI API Keyï¼ŒAI åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")
    
    def _init_openai_fallback(self) -> None:
        """
        åˆå§‹åŒ– OpenAI å…¼å®¹ API ä½œä¸ºå¤‡é€‰
        
        æ”¯æŒæ‰€æœ‰ OpenAI æ ¼å¼çš„ APIï¼ŒåŒ…æ‹¬ï¼š
        - OpenAI å®˜æ–¹
        - DeepSeek
        - é€šä¹‰åƒé—®
        - Moonshot ç­‰
        """
        config = get_config()
        
        # æ£€æŸ¥ OpenAI API Key æ˜¯å¦æœ‰æ•ˆï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
        openai_key_valid = (
            config.openai_api_key and 
            not config.openai_api_key.startswith('your_') and 
            len(config.openai_api_key) > 10
        )
        
        if not openai_key_valid:
            logger.debug("OpenAI å…¼å®¹ API æœªé…ç½®æˆ–é…ç½®æ— æ•ˆ")
            return
        
        # åˆ†ç¦» import å’Œå®¢æˆ·ç«¯åˆ›å»ºï¼Œä»¥ä¾¿æä¾›æ›´å‡†ç¡®çš„é”™è¯¯ä¿¡æ¯
        try:
            from openai import OpenAI
        except ImportError:
            logger.error("æœªå®‰è£… openai åº“ï¼Œè¯·è¿è¡Œ: pip install openai")
            return
        
        try:
            # base_url å¯é€‰ï¼Œä¸å¡«åˆ™ä½¿ç”¨ OpenAI å®˜æ–¹é»˜è®¤åœ°å€
            client_kwargs = {"api_key": config.openai_api_key}
            if config.openai_base_url and config.openai_base_url.startswith('http'):
                client_kwargs["base_url"] = config.openai_base_url
            
            self._openai_client = OpenAI(**client_kwargs)
            self._current_model_name = config.openai_model
            self._use_openai = True
            logger.info(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–æˆåŠŸ (base_url: {config.openai_base_url}, model: {config.openai_model})")
        except ImportError as e:
            # ä¾èµ–ç¼ºå¤±ï¼ˆå¦‚ socksioï¼‰
            if 'socksio' in str(e).lower() or 'socks' in str(e).lower():
                logger.error(f"OpenAI å®¢æˆ·ç«¯éœ€è¦ SOCKS ä»£ç†æ”¯æŒï¼Œè¯·è¿è¡Œ: pip install httpx[socks] æˆ– pip install socksio")
            else:
                logger.error(f"OpenAI ä¾èµ–ç¼ºå¤±: {e}")
        except Exception as e:
            error_msg = str(e).lower()
            if 'socks' in error_msg or 'socksio' in error_msg or 'proxy' in error_msg:
                logger.error(f"OpenAI ä»£ç†é…ç½®é”™è¯¯: {e}ï¼Œå¦‚ä½¿ç”¨ SOCKS ä»£ç†è¯·è¿è¡Œ: pip install httpx[socks]")
            else:
                logger.error(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _init_model(self) -> None:
        """
        åˆå§‹åŒ– Gemini æ¨¡å‹
        
        é…ç½®ï¼š
        - ä½¿ç”¨ gemini-3-flash-preview æˆ– gemini-2.5-flash æ¨¡å‹
        - ä¸å¯ç”¨ Google Searchï¼ˆä½¿ç”¨å¤–éƒ¨ Tavily/SerpAPI æœç´¢ï¼‰
        """
        try:
            import google.generativeai as genai
            
            # é…ç½® API Key
            genai.configure(api_key=self._api_key)
            
            # ä»é…ç½®è·å–æ¨¡å‹åç§°
            config = get_config()
            model_name = config.gemini_model
            fallback_model = config.gemini_model_fallback
            
            # ä¸å†ä½¿ç”¨ Google Search Groundingï¼ˆå·²çŸ¥æœ‰å…¼å®¹æ€§é—®é¢˜ï¼‰
            # æ”¹ä¸ºä½¿ç”¨å¤–éƒ¨æœç´¢æœåŠ¡ï¼ˆTavily/SerpAPIï¼‰é¢„å…ˆè·å–æ–°é—»
            
            # å°è¯•åˆå§‹åŒ–ä¸»æ¨¡å‹
            try:
                self._model = genai.GenerativeModel(
                    model_name=model_name,
                    system_instruction=self.SYSTEM_PROMPT,
                )
                self._current_model_name = model_name
                self._using_fallback = False
                logger.info(f"Gemini æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {model_name})")
            except Exception as model_error:
                # å°è¯•å¤‡é€‰æ¨¡å‹
                logger.warning(f"ä¸»æ¨¡å‹ {model_name} åˆå§‹åŒ–å¤±è´¥: {model_error}ï¼Œå°è¯•å¤‡é€‰æ¨¡å‹ {fallback_model}")
                self._model = genai.GenerativeModel(
                    model_name=fallback_model,
                    system_instruction=self.SYSTEM_PROMPT,
                )
                self._current_model_name = fallback_model
                self._using_fallback = True
                logger.info(f"Gemini å¤‡é€‰æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {fallback_model})")
            
        except Exception as e:
            logger.error(f"Gemini æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self._model = None
    
    def _switch_to_fallback_model(self) -> bool:
        """
        åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹
        
        Returns:
            æ˜¯å¦æˆåŠŸåˆ‡æ¢
        """
        try:
            import google.generativeai as genai
            config = get_config()
            fallback_model = config.gemini_model_fallback
            
            logger.warning(f"[LLM] åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹: {fallback_model}")
            self._model = genai.GenerativeModel(
                model_name=fallback_model,
                system_instruction=self.SYSTEM_PROMPT,
            )
            self._current_model_name = fallback_model
            self._using_fallback = True
            logger.info(f"[LLM] å¤‡é€‰æ¨¡å‹ {fallback_model} åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"[LLM] åˆ‡æ¢å¤‡é€‰æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def is_available(self) -> bool:
        """æ£€æŸ¥åˆ†æå™¨æ˜¯å¦å¯ç”¨"""
        return self._model is not None or self._openai_client is not None
    
    def _call_openai_api(self, prompt: str, generation_config: dict) -> str:
        """
        è°ƒç”¨ OpenAI å…¼å®¹ API
        
        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®
            
        Returns:
            å“åº”æ–‡æœ¬
        """
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay
        
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))
                    delay = min(delay, 60)
                    logger.info(f"[OpenAI] ç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)
                
                response = self._openai_client.chat.completions.create(
                    model=self._current_model_name,
                    messages=[
                        {"role": "system", "content": self.SYSTEM_PROMPT},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=generation_config.get('temperature', 0.7),
                    max_tokens=generation_config.get('max_output_tokens', 8192),
                )
                
                if response and response.choices and response.choices[0].message.content:
                    return response.choices[0].message.content
                else:
                    raise ValueError("OpenAI API è¿”å›ç©ºå“åº”")
                    
            except Exception as e:
                error_str = str(e)
                is_rate_limit = '429' in error_str or 'rate' in error_str.lower() or 'quota' in error_str.lower()
                
                if is_rate_limit:
                    logger.warning(f"[OpenAI] API é™æµï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                else:
                    logger.warning(f"[OpenAI] API è°ƒç”¨å¤±è´¥ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                
                if attempt == max_retries - 1:
                    raise
        
        raise Exception("OpenAI API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def _call_api_with_retry(self, prompt: str, generation_config: dict) -> str:
        """
        è°ƒç”¨ AI APIï¼Œå¸¦æœ‰é‡è¯•å’Œæ¨¡å‹åˆ‡æ¢æœºåˆ¶
        
        ä¼˜å…ˆçº§ï¼šGemini > Gemini å¤‡é€‰æ¨¡å‹ > OpenAI å…¼å®¹ API
        
        å¤„ç† 429 é™æµé”™è¯¯ï¼š
        1. å…ˆæŒ‡æ•°é€€é¿é‡è¯•
        2. å¤šæ¬¡å¤±è´¥ååˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹
        3. Gemini å®Œå…¨å¤±è´¥åå°è¯• OpenAI
        
        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®
            
        Returns:
            å“åº”æ–‡æœ¬
        """
        # å¦‚æœå·²ç»åœ¨ä½¿ç”¨ OpenAI æ¨¡å¼ï¼Œç›´æ¥è°ƒç”¨ OpenAI
        if self._use_openai:
            return self._call_openai_api(prompt, generation_config)
        
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay
        
        last_error = None
        tried_fallback = getattr(self, '_using_fallback', False)
        
        for attempt in range(max_retries):
            try:
                # è¯·æ±‚å‰å¢åŠ å»¶æ—¶ï¼ˆé˜²æ­¢è¯·æ±‚è¿‡å¿«è§¦å‘é™æµï¼‰
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))  # æŒ‡æ•°é€€é¿: 5, 10, 20, 40...
                    delay = min(delay, 60)  # æœ€å¤§60ç§’
                    logger.info(f"[Gemini] ç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)
                
                response = self._model.generate_content(
                    prompt,
                    generation_config=generation_config,
                    request_options={"timeout": 120}
                )
                
                if response and response.text:
                    return response.text
                else:
                    raise ValueError("Gemini è¿”å›ç©ºå“åº”")
                    
            except Exception as e:
                last_error = e
                error_str = str(e)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ 429 é™æµé”™è¯¯
                is_rate_limit = '429' in error_str or 'quota' in error_str.lower() or 'rate' in error_str.lower()
                
                if is_rate_limit:
                    logger.warning(f"[Gemini] API é™æµ (429)ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                    
                    # å¦‚æœå·²ç»é‡è¯•äº†ä¸€åŠæ¬¡æ•°ä¸”è¿˜æ²¡åˆ‡æ¢è¿‡å¤‡é€‰æ¨¡å‹ï¼Œå°è¯•åˆ‡æ¢
                    if attempt >= max_retries // 2 and not tried_fallback:
                        if self._switch_to_fallback_model():
                            tried_fallback = True
                            logger.info("[Gemini] å·²åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹ï¼Œç»§ç»­é‡è¯•")
                        else:
                            logger.warning("[Gemini] åˆ‡æ¢å¤‡é€‰æ¨¡å‹å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰æ¨¡å‹é‡è¯•")
                else:
                    # éé™æµé”™è¯¯ï¼Œè®°å½•å¹¶ç»§ç»­é‡è¯•
                    logger.warning(f"[Gemini] API è°ƒç”¨å¤±è´¥ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
        
        # Gemini æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œå°è¯• OpenAI å…¼å®¹ API
        if self._openai_client:
            logger.warning("[Gemini] æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œåˆ‡æ¢åˆ° OpenAI å…¼å®¹ API")
            try:
                return self._call_openai_api(prompt, generation_config)
            except Exception as openai_error:
                logger.error(f"[OpenAI] å¤‡é€‰ API ä¹Ÿå¤±è´¥: {openai_error}")
                raise last_error or openai_error
        elif config.openai_api_key and config.openai_base_url:
            # å°è¯•æ‡’åŠ è½½åˆå§‹åŒ– OpenAI
            logger.warning("[Gemini] æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œå°è¯•åˆå§‹åŒ– OpenAI å…¼å®¹ API")
            self._init_openai_fallback()
            if self._openai_client:
                try:
                    return self._call_openai_api(prompt, generation_config)
                except Exception as openai_error:
                    logger.error(f"[OpenAI] å¤‡é€‰ API ä¹Ÿå¤±è´¥: {openai_error}")
                    raise last_error or openai_error
        
        # æ‰€æœ‰æ–¹å¼éƒ½å¤±è´¥
        raise last_error or Exception("æ‰€æœ‰ AI API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def analyze(
        self, 
        context: Dict[str, Any],
        news_context: Optional[str] = None
    ) -> AnalysisResult:
        """
        åˆ†æå•åªè‚¡ç¥¨
        
        æµç¨‹ï¼š
        1. æ ¼å¼åŒ–è¾“å…¥æ•°æ®ï¼ˆæŠ€æœ¯é¢ + æ–°é—»ï¼‰
        2. è°ƒç”¨ Gemini APIï¼ˆå¸¦é‡è¯•å’Œæ¨¡å‹åˆ‡æ¢ï¼‰
        3. è§£æ JSON å“åº”
        4. è¿”å›ç»“æ„åŒ–ç»“æœ
        
        Args:
            context: ä» storage.get_analysis_context() è·å–çš„ä¸Šä¸‹æ–‡æ•°æ®
            news_context: é¢„å…ˆæœç´¢çš„æ–°é—»å†…å®¹ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            AnalysisResult å¯¹è±¡
        """
        code = context.get('code', 'Unknown')
        config = get_config()
        
        # è¯·æ±‚å‰å¢åŠ å»¶æ—¶ï¼ˆé˜²æ­¢è¿ç»­è¯·æ±‚è§¦å‘é™æµï¼‰
        request_delay = config.gemini_request_delay
        if request_delay > 0:
            logger.debug(f"[LLM] è¯·æ±‚å‰ç­‰å¾… {request_delay:.1f} ç§’...")
            time.sleep(request_delay)
        
        # ä¼˜å…ˆä»ä¸Šä¸‹æ–‡è·å–è‚¡ç¥¨åç§°ï¼ˆç”± main.py ä¼ å…¥ï¼‰
        name = context.get('stock_name')
        if not name or name.startswith('è‚¡ç¥¨'):
            # å¤‡é€‰ï¼šä» realtime ä¸­è·å–
            if 'realtime' in context and context['realtime'].get('name'):
                name = context['realtime']['name']
            else:
                # æœ€åä»æ˜ å°„è¡¨è·å–
                name = STOCK_NAME_MAP.get(code, f'è‚¡ç¥¨{code}')
        
        # å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤ç»“æœ
        if not self.is_available():
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction='éœ‡è¡',
                operation_advice='æŒæœ‰',
                confidence_level='ä½',
                analysis_summary='AI åˆ†æåŠŸèƒ½æœªå¯ç”¨ï¼ˆæœªé…ç½® API Keyï¼‰',
                risk_warning='è¯·é…ç½® Gemini API Key åé‡è¯•',
                success=False,
                error_message='Gemini API Key æœªé…ç½®',
            )
        
        try:
            # æ ¼å¼åŒ–è¾“å…¥ï¼ˆåŒ…å«æŠ€æœ¯é¢æ•°æ®å’Œæ–°é—»ï¼‰
            prompt = self._format_prompt(context, name, news_context)
            
            # è·å–æ¨¡å‹åç§°
            model_name = getattr(self, '_current_model_name', None)
            if not model_name:
                model_name = getattr(self._model, '_model_name', 'unknown')
                if hasattr(self._model, 'model_name'):
                    model_name = self._model.model_name
            
            logger.info(f"========== AI åˆ†æ {name}({code}) ==========")
            logger.info(f"[LLMé…ç½®] æ¨¡å‹: {model_name}")
            logger.info(f"[LLMé…ç½®] Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
            logger.info(f"[LLMé…ç½®] æ˜¯å¦åŒ…å«æ–°é—»: {'æ˜¯' if news_context else 'å¦'}")
            
            # è®°å½•å®Œæ•´ prompt åˆ°æ—¥å¿—ï¼ˆINFOçº§åˆ«è®°å½•æ‘˜è¦ï¼ŒDEBUGè®°å½•å®Œæ•´ï¼‰
            prompt_preview = prompt[:500] + "..." if len(prompt) > 500 else prompt
            logger.info(f"[LLM Prompt é¢„è§ˆ]\n{prompt_preview}")
            logger.debug(f"=== å®Œæ•´ Prompt ({len(prompt)}å­—ç¬¦) ===\n{prompt}\n=== End Prompt ===")
            
            # è®¾ç½®ç”Ÿæˆé…ç½®
            generation_config = {
                "temperature": 0.7,
                "max_output_tokens": 8192,
            }
            
            logger.info(f"[LLMè°ƒç”¨] å¼€å§‹è°ƒç”¨ Gemini API (temperature={generation_config['temperature']}, max_tokens={generation_config['max_output_tokens']})...")
            
            # ä½¿ç”¨å¸¦é‡è¯•çš„ API è°ƒç”¨
            start_time = time.time()
            response_text = self._call_api_with_retry(prompt, generation_config)
            elapsed = time.time() - start_time
            
            # è®°å½•å“åº”ä¿¡æ¯
            logger.info(f"[LLMè¿”å›] Gemini API å“åº”æˆåŠŸ, è€—æ—¶ {elapsed:.2f}s, å“åº”é•¿åº¦ {len(response_text)} å­—ç¬¦")
            
            # è®°å½•å“åº”é¢„è§ˆï¼ˆINFOçº§åˆ«ï¼‰å’Œå®Œæ•´å“åº”ï¼ˆDEBUGçº§åˆ«ï¼‰
            response_preview = response_text[:300] + "..." if len(response_text) > 300 else response_text
            logger.info(f"[LLMè¿”å› é¢„è§ˆ]\n{response_preview}")
            logger.debug(f"=== Gemini å®Œæ•´å“åº” ({len(response_text)}å­—ç¬¦) ===\n{response_text}\n=== End Response ===")
            
            # è§£æå“åº”
            result = self._parse_response(response_text, code, name)
            result.raw_response = response_text
            result.search_performed = bool(news_context)
            
            # [CRITICAL Fix] å¼ºåˆ¶æ³¨å…¥ Python è®¡ç®—çš„çœŸå®è‚¡æ¯ç‡æ•°æ®ï¼ˆé˜²æ­¢ AI å¹»è§‰æˆ–é—æ¼ï¼‰
            try:
                if 'dividend_analysis' in context:
                    calc_div = context['dividend_analysis']
                    if result.dashboard is None:
                        result.dashboard = {}
                    
                    if 'dividend_analysis' not in result.dashboard:
                        result.dashboard['dividend_analysis'] = {}
                    
                    # è¦†ç›–æ•°å€¼ (ç¡®ä¿å‰ç«¯æ˜¾ç¤ºæ­£ç¡®æ•°å€¼)
                    yield_val = calc_div.get('expected_yield', 0)
                    result.dashboard['dividend_analysis']['dividend_yield'] = yield_val
                    
                    # è¡¥å……ç®—ç† (AI çš„è¯„è®ºå¯èƒ½å¤ªæ³›ï¼Œè¡¥å…… Python çš„ç²¾ç¡®é€»è¾‘)
                    ai_comment = result.dashboard['dividend_analysis'].get('dividend_comment', '')
                    calc_reason = calc_div.get('reason', '')
                    # å¦‚æœ AI æ²¡å†™æˆ–è€…ä¸ä¸€æ ·ï¼Œè¿½åŠ è¯´æ˜
                    combined_comment = f"{ai_comment} [ç®—æ³•ç¡®è¯: {calc_reason}]".strip()
                    result.dashboard['dividend_analysis']['dividend_comment'] = combined_comment
                    
                    logger.info(f"å·²å¼ºåˆ¶æ³¨å…¥è‚¡æ¯ç‡æ•°æ®: {yield_val}%")
            except Exception as div_err:
                logger.warning(f"è‚¡æ¯ç‡æ•°æ®æ³¨å…¥å¤±è´¥: {div_err}")

            # [CRITICAL Fix] å¼ºåˆ¶æ³¨å…¥ä¼°å€¼/åŒä¸š/ç­¹ç ç­‰Pythonæ•°æ®ï¼ˆç¡®ä¿æŠ¥å‘Šå±•ç¤ºï¼‰
            try:
                if result.dashboard is None:
                    result.dashboard = {}
                    
                # æ³¨å…¥10å¹´PEåˆ†ä½æ•°æ®
                if 'valuation_history' in context and context['valuation_history']:
                    result.dashboard['valuation_history'] = context['valuation_history']
                    logger.debug(f"å·²æ³¨å…¥ä¼°å€¼å†å²æ•°æ®: PEåˆ†ä½={context['valuation_history'].get('pe_rank_10y', 0):.1f}%")
                
                # æ³¨å…¥åŒä¸šæ¯”ä»·æ•°æ®
                if 'peer_comparison' in context and context['peer_comparison']:
                    result.dashboard['peer_comparison'] = context['peer_comparison']
                    logger.debug(f"å·²æ³¨å…¥åŒä¸šæ¯”ä»·æ•°æ®")
                
                # æ³¨å…¥ç­¹ç åˆ†å¸ƒæ•°æ®
                if 'chip' in context and context['chip']:
                    result.dashboard['chip_data'] = context['chip']
                    logger.debug(f"å·²æ³¨å…¥ç­¹ç æ•°æ®")
                
                # æ³¨å…¥å®æ—¶è¡Œæƒ…æ•°æ®
                if 'realtime' in context and context['realtime']:
                    result.dashboard['realtime'] = context['realtime']
                    logger.debug(f"å·²æ³¨å…¥å®æ—¶è¡Œæƒ…æ•°æ®")
                
                # æ³¨å…¥ä¹°ç‚¹åˆ†ææ•°æ®
                if 'buy_point' in context and context['buy_point']:
                    result.dashboard['buy_point'] = context['buy_point']
                    logger.info(f"å·²æ³¨å…¥ä¹°ç‚¹åˆ†ææ•°æ®: {context['buy_point'].get('label', '')} {context['buy_point'].get('label_text', '')}")
                    
            except Exception as inject_err:
                logger.warning(f"æ‰©å±•æ•°æ®æ³¨å…¥å¤±è´¥: {inject_err}")

            logger.info(f"[LLMè§£æ] {name}({code}) åˆ†æå®Œæˆ: {result.trend_prediction}, è¯„åˆ† {result.sentiment_score}")
            
            return result
            
        except Exception as e:
            logger.error(f"AI åˆ†æ {name}({code}) å¤±è´¥: {e}")
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction='éœ‡è¡',
                operation_advice='æŒæœ‰',
                confidence_level='ä½',
                analysis_summary=f'åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)[:100]}',
                risk_warning='åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•æˆ–æ‰‹åŠ¨åˆ†æ',
                success=False,
                error_message=str(e),
            )
    
    def _format_prompt(
        self, 
        context: Dict[str, Any], 
        name: str,
        news_context: Optional[str] = None
    ) -> str:
        """
        æ ¼å¼åŒ–åˆ†ææç¤ºè¯ï¼ˆå†³ç­–ä»ªè¡¨ç›˜ v2.0ï¼‰
        
        åŒ…å«ï¼šæŠ€æœ¯æŒ‡æ ‡ã€å®æ—¶è¡Œæƒ…ï¼ˆé‡æ¯”/æ¢æ‰‹ç‡ï¼‰ã€ç­¹ç åˆ†å¸ƒã€è¶‹åŠ¿åˆ†æã€æ–°é—»
        
        Args:
            context: æŠ€æœ¯é¢æ•°æ®ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å¢å¼ºæ•°æ®ï¼‰
            name: è‚¡ç¥¨åç§°ï¼ˆé»˜è®¤å€¼ï¼Œå¯èƒ½è¢«ä¸Šä¸‹æ–‡è¦†ç›–ï¼‰
            news_context: é¢„å…ˆæœç´¢çš„æ–°é—»å†…å®¹
        """
        code = context.get('code', 'Unknown')
        
        # ä¼˜å…ˆä½¿ç”¨ä¸Šä¸‹æ–‡ä¸­çš„è‚¡ç¥¨åç§°ï¼ˆä» realtime_quote è·å–ï¼‰
        stock_name = context.get('stock_name', name)
        if not stock_name or stock_name == f'è‚¡ç¥¨{code}':
            stock_name = STOCK_NAME_MAP.get(code, f'è‚¡ç¥¨{code}')
            
        today = context.get('today', {})
        
        # ========== æ„å»ºå†³ç­–ä»ªè¡¨ç›˜æ ¼å¼çš„è¾“å…¥ ==========
        prompt = f"""# å†³ç­–ä»ªè¡¨ç›˜åˆ†æè¯·æ±‚

## ğŸ“Š è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
| é¡¹ç›® | æ•°æ® |
|------|------|
| è‚¡ç¥¨ä»£ç  | **{code}** |
| è‚¡ç¥¨åç§° | **{stock_name}** |
| åˆ†ææ—¥æœŸ | {context.get('date', 'æœªçŸ¥')} |

---

## ğŸ“ˆ æŠ€æœ¯é¢æ•°æ®

### ä»Šæ—¥è¡Œæƒ…
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ”¶ç›˜ä»· | {today.get('close', 'N/A')} å…ƒ |
| å¼€ç›˜ä»· | {today.get('open', 'N/A')} å…ƒ |
| æœ€é«˜ä»· | {today.get('high', 'N/A')} å…ƒ |
| æœ€ä½ä»· | {today.get('low', 'N/A')} å…ƒ |
| æ¶¨è·Œå¹… | {today.get('pct_chg', 'N/A')}% |
| æˆäº¤é‡ | {self._format_volume(today.get('volume'))} |
| æˆäº¤é¢ | {self._format_amount(today.get('amount'))} |

### å‡çº¿ç³»ç»Ÿï¼ˆå…³é”®åˆ¤æ–­æŒ‡æ ‡ï¼‰
| å‡çº¿ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| MA5 | {today.get('ma5', 'N/A')} | çŸ­æœŸè¶‹åŠ¿çº¿ |
| MA10 | {today.get('ma10', 'N/A')} | ä¸­çŸ­æœŸè¶‹åŠ¿çº¿ |
| MA20 | {today.get('ma20', 'N/A')} | ä¸­æœŸè¶‹åŠ¿çº¿ |
| å‡çº¿å½¢æ€ | {context.get('ma_status', 'æœªçŸ¥')} | å¤šå¤´/ç©ºå¤´/ç¼ ç»• |
"""
        
        # æ·»åŠ å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆé‡æ¯”ã€æ¢æ‰‹ç‡ç­‰ï¼‰
        if 'realtime' in context:
            rt = context['realtime']
            prompt += f"""
### å®æ—¶è¡Œæƒ…å¢å¼ºæ•°æ®
| æŒ‡æ ‡ | æ•°å€¼ | è§£è¯» |
|------|------|------|
| å½“å‰ä»·æ ¼ | {rt.get('price', 'N/A')} å…ƒ | |
| **é‡æ¯”** | **{rt.get('volume_ratio', 'N/A')}** | {rt.get('volume_ratio_desc', '')} |
| **æ¢æ‰‹ç‡** | **{rt.get('turnover_rate', 'N/A')}%** | |
| å¸‚ç›ˆç‡(åŠ¨æ€) | {rt.get('pe_ratio', 'N/A')} | |
| å¸‚å‡€ç‡ | {rt.get('pb_ratio', 'N/A')} | |
| æ€»å¸‚å€¼ | {self._format_amount(rt.get('total_mv'))} | |
| æµé€šå¸‚å€¼ | {self._format_amount(rt.get('circ_mv'))} | |
| 60æ—¥æ¶¨è·Œå¹… | {rt.get('change_60d', 'N/A')}% | ä¸­æœŸè¡¨ç° |
"""
        
        # æ·»åŠ ç­¹ç åˆ†å¸ƒæ•°æ®
        if 'chip' in context:
            chip = context['chip']
            profit_ratio = chip.get('profit_ratio', 0)
            prompt += f"""
### ç­¹ç åˆ†å¸ƒæ•°æ®ï¼ˆæ•ˆç‡æŒ‡æ ‡ï¼‰
| æŒ‡æ ‡ | æ•°å€¼ | å¥åº·æ ‡å‡† |
|------|------|----------|
| **è·åˆ©æ¯”ä¾‹** | **{profit_ratio:.1%}** | 70-90%æ—¶è­¦æƒ• |
| å¹³å‡æˆæœ¬ | {chip.get('avg_cost', 'N/A')} å…ƒ | ç°ä»·åº”é«˜äº5-15% |
| 90%ç­¹ç é›†ä¸­åº¦ | {chip.get('concentration_90', 0):.2%} | <15%ä¸ºé›†ä¸­ |
| 70%ç­¹ç é›†ä¸­åº¦ | {chip.get('concentration_70', 0):.2%} | |
| ç­¹ç çŠ¶æ€ | {chip.get('chip_status', 'æœªçŸ¥')} | |
"""

        # æ·»åŠ  Dangæ°è‚¡æ¯åˆ†æç»“æœ
        if 'dividend_analysis' in context:
            div = context['dividend_analysis']
            prompt += f"""
### ğŸ’° Dangæ°é¢„æœŸè‚¡æ¯åˆ†æ
| æŒ‡æ ‡ | æ•°å€¼ | åˆ¤å®šæ ‡å‡† |
|------|------|----------|
| **é¢„æœŸè‚¡æ¯ç‡** | **{div.get('expected_yield', 0):.2f}%** | >5%ä¸ºä¼˜è´¨ç”Ÿäº§èµ„æ–™ |
| è®¡ç®—é€»è¾‘ | {div.get('reason', 'N/A')} | |
"""

        # æ·»åŠ å†å²ä¼°å€¼åˆ†ä½ (V4.0 Upgrade)
        if 'valuation_history' in context and context['valuation_history']:
            val_hist = context['valuation_history']
            prompt += f"""
### ğŸ“Š ç»å¯¹ä¼°å€¼å®‰å…¨åº¦ (çºµå‘å†å²)
| æŒ‡æ ‡ | å½“å‰å€¼ | 10å¹´åˆ†ä½ | åˆ¤å®š |
|------|--------|----------|------|
| **PE(TTM)** | **{val_hist.get('current_pe', 0):.2f}** | **{val_hist.get('pe_rank_10y', 0):.1f}%** | {"âœ… åº•éƒ¨åŒºåŸŸ" if val_hist.get('pe_rank_10y', 0)<20 else "âš ï¸ åé«˜"} |
"""

        # æ·»åŠ åŒä¸šæ¯”ä»· (V4.0 Upgrade)
        if 'peer_comparison' in context and context['peer_comparison']:
            peers = context['peer_comparison']
            prompt += f"""
### ğŸ‘¥ åŒä¸šæ¯”ä»· (æ¨ªå‘å¯¹æ¯”)
| è¡Œä¸š | è¡Œä¸šä¸­ä½PE | è¡Œä¸šé¾™å¤´ |
|------|------------|----------|
| {peers.get('industry', 'æœªçŸ¥')} | {peers.get('avg_pe', 0):.2f} | {', '.join(peers.get('top_peers', [])[:3])} |

*æ³¨ï¼šè¯·å°†å½“å‰PEä¸è¡Œä¸šä¸­ä½PEå¯¹æ¯”ï¼Œè®¡ç®—æŠ˜ä»·ç‡ã€‚*
"""
        
        # æ·»åŠ è¶‹åŠ¿åˆ†æç»“æœï¼ˆåŸºäºäº¤æ˜“ç†å¿µçš„é¢„åˆ¤ï¼‰
        if 'trend_analysis' in context:
            trend = context['trend_analysis']
            bias_warning = "ğŸš¨ è¶…è¿‡5%ï¼Œä¸¥ç¦è¿½é«˜ï¼" if trend.get('bias_ma5', 0) > 5 else "âœ… å®‰å…¨èŒƒå›´"
            prompt += f"""
### è¶‹åŠ¿åˆ†æé¢„åˆ¤ï¼ˆåŸºäºäº¤æ˜“ç†å¿µï¼‰
| æŒ‡æ ‡ | æ•°å€¼ | åˆ¤å®š |
|------|------|------|
| è¶‹åŠ¿çŠ¶æ€ | {trend.get('trend_status', 'æœªçŸ¥')} | |
| å‡çº¿æ’åˆ— | {trend.get('ma_alignment', 'æœªçŸ¥')} | MA5>MA10>MA20ä¸ºå¤šå¤´ |
| è¶‹åŠ¿å¼ºåº¦ | {trend.get('trend_strength', 0)}/100 | |
| **ä¹–ç¦»ç‡(MA5)** | **{trend.get('bias_ma5', 0):+.2f}%** | {bias_warning} |
| ä¹–ç¦»ç‡(MA10) | {trend.get('bias_ma10', 0):+.2f}% | |
| é‡èƒ½çŠ¶æ€ | {trend.get('volume_status', 'æœªçŸ¥')} | {trend.get('volume_trend', '')} |
| ç³»ç»Ÿä¿¡å· | {trend.get('buy_signal', 'æœªçŸ¥')} | |
| ç³»ç»Ÿè¯„åˆ† | {trend.get('signal_score', 0)}/100 | |

#### ç³»ç»Ÿåˆ†æç†ç”±
**ä¹°å…¥ç†ç”±**ï¼š
{chr(10).join('- ' + r for r in trend.get('signal_reasons', ['æ— '])) if trend.get('signal_reasons') else '- æ— '}

**é£é™©å› ç´ **ï¼š
{chr(10).join('- ' + r for r in trend.get('risk_factors', ['æ— '])) if trend.get('risk_factors') else '- æ— '}
"""
        
        # æ·»åŠ æ˜¨æ—¥å¯¹æ¯”æ•°æ®
        if 'yesterday' in context:
            volume_change = context.get('volume_change_ratio', 'N/A')
            prompt += f"""
### é‡ä»·å˜åŒ–
- æˆäº¤é‡è¾ƒæ˜¨æ—¥å˜åŒ–ï¼š{volume_change}å€
- ä»·æ ¼è¾ƒæ˜¨æ—¥å˜åŒ–ï¼š{context.get('price_change_ratio', 'N/A')}%
"""
        
        # æ·»åŠ æ–°é—»æœç´¢ç»“æœï¼ˆé‡ç‚¹åŒºåŸŸï¼‰
        prompt += """
---

## ğŸ“° èˆ†æƒ…æƒ…æŠ¥
"""
        if news_context:
            prompt += f"""
ä»¥ä¸‹æ˜¯ **{stock_name}({code})** è¿‘7æ—¥çš„æ–°é—»æœç´¢ç»“æœï¼Œè¯·é‡ç‚¹æå–ï¼š
1. ğŸš¨ **é£é™©è­¦æŠ¥**ï¼šå‡æŒã€å¤„ç½šã€åˆ©ç©º
2. ğŸ¯ **åˆ©å¥½å‚¬åŒ–**ï¼šä¸šç»©ã€åˆåŒã€æ”¿ç­–
3. ğŸ“Š **ä¸šç»©é¢„æœŸ**ï¼šå¹´æŠ¥é¢„å‘Šã€ä¸šç»©å¿«æŠ¥

```
{news_context}
```
"""
        else:
            prompt += """
æœªæœç´¢åˆ°è¯¥è‚¡ç¥¨è¿‘æœŸçš„ç›¸å…³æ–°é—»ã€‚è¯·ä¸»è¦ä¾æ®æŠ€æœ¯é¢æ•°æ®è¿›è¡Œåˆ†æã€‚
"""
        
        # æ˜ç¡®çš„è¾“å‡ºè¦æ±‚
        prompt += f"""
---

## âœ… åˆ†æä»»åŠ¡

è¯·ä¸º **{stock_name}({code})** ç”Ÿæˆã€å†³ç­–ä»ªè¡¨ç›˜ã€‘ï¼Œä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºã€‚

### é‡ç‚¹å…³æ³¨ï¼ˆå¿…é¡»æ˜ç¡®å›ç­”ï¼‰ï¼š
1. â“ æ˜¯å¦æ»¡è¶³ MA5>MA10>MA20 å¤šå¤´æ’åˆ—ï¼Ÿ
2. â“ å½“å‰ä¹–ç¦»ç‡æ˜¯å¦åœ¨å®‰å…¨èŒƒå›´å†…ï¼ˆ<5%ï¼‰ï¼Ÿâ€”â€” è¶…è¿‡5%å¿…é¡»æ ‡æ³¨"ä¸¥ç¦è¿½é«˜"
3. â“ é‡èƒ½æ˜¯å¦é…åˆï¼ˆç¼©é‡å›è°ƒ/æ”¾é‡çªç ´ï¼‰ï¼Ÿ
4. â“ ç­¹ç ç»“æ„æ˜¯å¦å¥åº·ï¼Ÿ
5. â“ æ¶ˆæ¯é¢æœ‰æ— é‡å¤§åˆ©ç©ºï¼Ÿï¼ˆå‡æŒã€å¤„ç½šã€ä¸šç»©å˜è„¸ç­‰ï¼‰

### å†³ç­–ä»ªè¡¨ç›˜è¦æ±‚ï¼š
- **æ ¸å¿ƒç»“è®º**ï¼šä¸€å¥è¯è¯´æ¸…è¯¥ä¹°/è¯¥å–/è¯¥ç­‰
- **æŒä»“åˆ†ç±»å»ºè®®**ï¼šç©ºä»“è€…æ€ä¹ˆåš vs æŒä»“è€…æ€ä¹ˆåš
- **å…·ä½“ç‹™å‡»ç‚¹ä½**ï¼šä¹°å…¥ä»·ã€æ­¢æŸä»·ã€ç›®æ ‡ä»·ï¼ˆç²¾ç¡®åˆ°åˆ†ï¼‰
- **æ£€æŸ¥æ¸…å•**ï¼šæ¯é¡¹ç”¨ âœ…/âš ï¸/âŒ æ ‡è®°

è¯·è¾“å‡ºå®Œæ•´çš„ JSON æ ¼å¼å†³ç­–ä»ªè¡¨ç›˜ã€‚"""
        
        return prompt
    
    def _format_volume(self, volume: Optional[float]) -> str:
        """æ ¼å¼åŒ–æˆäº¤é‡æ˜¾ç¤º"""
        if volume is None:
            return 'N/A'
        if volume >= 1e8:
            return f"{volume / 1e8:.2f} äº¿è‚¡"
        elif volume >= 1e4:
            return f"{volume / 1e4:.2f} ä¸‡è‚¡"
        else:
            return f"{volume:.0f} è‚¡"
    
    def _format_amount(self, amount: Optional[float]) -> str:
        """æ ¼å¼åŒ–æˆäº¤é¢æ˜¾ç¤º"""
        if amount is None:
            return 'N/A'
        if amount >= 1e8:
            return f"{amount / 1e8:.2f} äº¿å…ƒ"
        elif amount >= 1e4:
            return f"{amount / 1e4:.2f} ä¸‡å…ƒ"
        else:
            return f"{amount:.0f} å…ƒ"
    
    def _parse_response(
        self, 
        response_text: str, 
        code: str, 
        name: str
    ) -> AnalysisResult:
        """
        è§£æ Gemini å“åº”ï¼ˆå†³ç­–ä»ªè¡¨ç›˜ç‰ˆï¼‰
        
        å°è¯•ä»å“åº”ä¸­æå– JSON æ ¼å¼çš„åˆ†æç»“æœï¼ŒåŒ…å« dashboard å­—æ®µ
        å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æ™ºèƒ½æå–æˆ–è¿”å›é»˜è®¤ç»“æœ
        """
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼šç§»é™¤ markdown ä»£ç å—æ ‡è®°
            cleaned_text = response_text
            if '```json' in cleaned_text:
                cleaned_text = cleaned_text.replace('```json', '').replace('```', '')
            elif '```' in cleaned_text:
                cleaned_text = cleaned_text.replace('```', '')
            
            # å°è¯•æ‰¾åˆ° JSON å†…å®¹
            json_start = cleaned_text.find('{')
            json_end = cleaned_text.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = cleaned_text[json_start:json_end]
                
                # å°è¯•ä¿®å¤å¸¸è§çš„ JSON é—®é¢˜
                json_str = self._fix_json_string(json_str)
                
                data = json.loads(json_str)
                
                # æå– dashboard æ•°æ®
                dashboard = data.get('dashboard', None)
                
                # è§£ææ‰€æœ‰å­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼é˜²æ­¢ç¼ºå¤±
                return AnalysisResult(
                    code=code,
                    name=name,
                    # æ ¸å¿ƒæŒ‡æ ‡
                    sentiment_score=int(data.get('sentiment_score', 50)),
                    trend_prediction=data.get('trend_prediction', 'éœ‡è¡'),
                    operation_advice=data.get('operation_advice', 'æŒæœ‰'),
                    confidence_level=data.get('confidence_level', 'ä¸­'),
                    # å†³ç­–ä»ªè¡¨ç›˜
                    dashboard=dashboard,
                    # èµ°åŠ¿åˆ†æ
                    trend_analysis=data.get('trend_analysis', ''),
                    short_term_outlook=data.get('short_term_outlook', ''),
                    medium_term_outlook=data.get('medium_term_outlook', ''),
                    # æŠ€æœ¯é¢
                    technical_analysis=data.get('technical_analysis', ''),
                    ma_analysis=data.get('ma_analysis', ''),
                    volume_analysis=data.get('volume_analysis', ''),
                    pattern_analysis=data.get('pattern_analysis', ''),
                    # åŸºæœ¬é¢
                    fundamental_analysis=data.get('fundamental_analysis', ''),
                    sector_position=data.get('sector_position', ''),
                    company_highlights=data.get('company_highlights', ''),
                    # æƒ…ç»ªé¢/æ¶ˆæ¯é¢
                    news_summary=data.get('news_summary', ''),
                    market_sentiment=data.get('market_sentiment', ''),
                    hot_topics=data.get('hot_topics', ''),
                    # ç»¼åˆ
                    analysis_summary=data.get('analysis_summary', 'åˆ†æå®Œæˆ'),
                    key_points=data.get('key_points', ''),
                    risk_warning=data.get('risk_warning', ''),
                    buy_reason=data.get('buy_reason', ''),
                    # å…ƒæ•°æ®
                    search_performed=data.get('search_performed', False),
                    data_sources=data.get('data_sources', 'æŠ€æœ¯é¢æ•°æ®'),
                    success=True,
                )
            else:
                # æ²¡æœ‰æ‰¾åˆ° JSONï¼Œå°è¯•ä»çº¯æ–‡æœ¬ä¸­æå–ä¿¡æ¯
                logger.warning(f"æ— æ³•ä»å“åº”ä¸­æå– JSONï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬åˆ†æ")
                return self._parse_text_response(response_text, code, name)
                
        except json.JSONDecodeError as e:
            logger.warning(f"JSON è§£æå¤±è´¥: {e}ï¼Œå°è¯•ä»æ–‡æœ¬æå–")
            return self._parse_text_response(response_text, code, name)
    
    def _fix_json_string(self, json_str: str) -> str:
        """ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜"""
        import re
        
        # ç§»é™¤æ³¨é‡Š
        json_str = re.sub(r'//.*?\n', '\n', json_str)
        json_str = re.sub(r'/\*.*?\*/', '', json_str, flags=re.DOTALL)
        
        # ä¿®å¤å°¾éšé€—å·
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        
        # ç¡®ä¿å¸ƒå°”å€¼æ˜¯å°å†™
        json_str = json_str.replace('True', 'true').replace('False', 'false')
        
        return json_str
    
    def _parse_text_response(
        self, 
        response_text: str, 
        code: str, 
        name: str
    ) -> AnalysisResult:
        """ä»çº¯æ–‡æœ¬å“åº”ä¸­å°½å¯èƒ½æå–åˆ†æä¿¡æ¯"""
        # å°è¯•è¯†åˆ«å…³é”®è¯æ¥åˆ¤æ–­æƒ…ç»ª
        sentiment_score = 50
        trend = 'éœ‡è¡'
        advice = 'æŒæœ‰'
        
        text_lower = response_text.lower()
        
        # ç®€å•çš„æƒ…ç»ªè¯†åˆ«
        positive_keywords = ['çœ‹å¤š', 'ä¹°å…¥', 'ä¸Šæ¶¨', 'çªç ´', 'å¼ºåŠ¿', 'åˆ©å¥½', 'åŠ ä»“', 'bullish', 'buy']
        negative_keywords = ['çœ‹ç©º', 'å–å‡º', 'ä¸‹è·Œ', 'è·Œç ´', 'å¼±åŠ¿', 'åˆ©ç©º', 'å‡ä»“', 'bearish', 'sell']
        
        positive_count = sum(1 for kw in positive_keywords if kw in text_lower)
        negative_count = sum(1 for kw in negative_keywords if kw in text_lower)
        
        if positive_count > negative_count + 1:
            sentiment_score = 65
            trend = 'çœ‹å¤š'
            advice = 'ä¹°å…¥'
        elif negative_count > positive_count + 1:
            sentiment_score = 35
            trend = 'çœ‹ç©º'
            advice = 'å–å‡º'
        
        # æˆªå–å‰500å­—ç¬¦ä½œä¸ºæ‘˜è¦
        summary = response_text[:500] if response_text else 'æ— åˆ†æç»“æœ'
        
        return AnalysisResult(
            code=code,
            name=name,
            sentiment_score=sentiment_score,
            trend_prediction=trend,
            operation_advice=advice,
            confidence_level='ä½',
            analysis_summary=summary,
            key_points='JSONè§£æå¤±è´¥ï¼Œä»…ä¾›å‚è€ƒ',
            risk_warning='åˆ†æç»“æœå¯èƒ½ä¸å‡†ç¡®ï¼Œå»ºè®®ç»“åˆå…¶ä»–ä¿¡æ¯åˆ¤æ–­',
            raw_response=response_text,
            success=True,
        )
    
    def batch_analyze(
        self, 
        contexts: List[Dict[str, Any]],
        delay_between: float = 2.0
    ) -> List[AnalysisResult]:
        """
        æ‰¹é‡åˆ†æå¤šåªè‚¡ç¥¨
        
        æ³¨æ„ï¼šä¸ºé¿å… API é€Ÿç‡é™åˆ¶ï¼Œæ¯æ¬¡åˆ†æä¹‹é—´ä¼šæœ‰å»¶è¿Ÿ
        
        Args:
            contexts: ä¸Šä¸‹æ–‡æ•°æ®åˆ—è¡¨
            delay_between: æ¯æ¬¡åˆ†æä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
            
        Returns:
            AnalysisResult åˆ—è¡¨
        """
        results = []
        
        for i, context in enumerate(contexts):
            if i > 0:
                logger.debug(f"ç­‰å¾… {delay_between} ç§’åç»§ç»­...")
                time.sleep(delay_between)
            
            result = self.analyze(context)
            results.append(result)
        
        return results


# ä¾¿æ·å‡½æ•°
def get_analyzer() -> GeminiAnalyzer:
    """è·å– Gemini åˆ†æå™¨å®ä¾‹"""
    return GeminiAnalyzer()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.DEBUG)
    
    # æ¨¡æ‹Ÿä¸Šä¸‹æ–‡æ•°æ®
    test_context = {
        'code': '600519',
        'date': '2026-01-09',
        'today': {
            'open': 1800.0,
            'high': 1850.0,
            'low': 1780.0,
            'close': 1820.0,
            'volume': 10000000,
            'amount': 18200000000,
            'pct_chg': 1.5,
            'ma5': 1810.0,
            'ma10': 1800.0,
            'ma20': 1790.0,
            'volume_ratio': 1.2,
        },
        'ma_status': 'å¤šå¤´æ’åˆ— ğŸ“ˆ',
        'volume_change_ratio': 1.3,
        'price_change_ratio': 1.5,
    }
    
    analyzer = GeminiAnalyzer()
    
    if analyzer.is_available():
        print("=== AI åˆ†ææµ‹è¯• ===")
        result = analyzer.analyze(test_context)
        print(f"åˆ†æç»“æœ: {result.to_dict()}")
    else:
        print("Gemini API æœªé…ç½®ï¼Œè·³è¿‡æµ‹è¯•")
